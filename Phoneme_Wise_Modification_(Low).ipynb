{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ngG2ldKDZ1ZSb06XuAAtf5RHqcuuKz5A",
      "authorship_tag": "ABX9TyNO95ShAv3MIVmO4xLqSsIj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Phoneme-wise modification of audio**\n",
        "---\n",
        "This code can be used to modify/alter the pitch, duration and energy of an audio file, provided, there is a well-documented transcript available for the particular phoneme of the audio file that is required to be modified.<br><br>**Note:** This code is programmed with the limitation that the transcript file should only contain the timestamps of the phoneme to be modified, and nothing else."
      ],
      "metadata": {
        "id": "sYOPVdPSO5w8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code has been written in Python and the audio modification functions have been written using PyWorld, a Python wrapper for WORLD vocoder (see [Python-Wrapper-for-World-Vocoder](https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder)). The [source file](https://drive.google.com/file/d/15nDAprE0FkmMHzH4HQNa7YgIg5jWH2iN/view?usp=share_link) containing all the functions of PyWorld needs to be present in the present working directory for the relevant functions to be imported and used in the code."
      ],
      "metadata": {
        "id": "sglq71FOxhl3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is used for unzipping the zipped source file containing the PyWorld functions."
      ],
      "metadata": {
        "id": "msbq-Q--D6AL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/PythonWORLDmaster.zip"
      ],
      "metadata": {
        "id": "MwuDp0m5KT8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the relevant modules and their functions need to be imported by running the following cell."
      ],
      "metadata": {
        "id": "bCvCdc7zEf4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wavread\n",
        "from scipy.io.wavfile import write as wavwrite\n",
        "from scipy import signal\n",
        "from scipy.io import savemat\n",
        "!pip install pysoundfile\n",
        "!pip install bitstring\n",
        "import IPython\n",
        "import wave\n",
        "import contextlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "NZCslWmU6h31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the source file has been unzipped, the present working directory needs to be changed to it, so that it can be used by running the following cell."
      ],
      "metadata": {
        "id": "Br5JaAp9E7OK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Python-WORLD-master"
      ],
      "metadata": {
        "id": "wCC7xg9QKZDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the **main** program from the list of defined programs in the **world** module needs to be imported."
      ],
      "metadata": {
        "id": "Pfw_2tFyHQw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from world import main"
      ],
      "metadata": {
        "id": "WRfRXmlKKaPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From **main**, the **World** class is called."
      ],
      "metadata": {
        "id": "UM4bgONjRw1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocoder = main.World()"
      ],
      "metadata": {
        "id": "K2NkjgQZKdxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell contains a list of all the phonemes, defined in the TIMIT corpus, in the same order as mentioned in their list of phonemes irrespective of category, in a single dimensional list.<br><br>**Note:** The following code might give faulty results, if the order of these phonemes is changed. Although no explicit bounds are defined in the list to segregate them into different categories, the phonemes are defined in a certain order so as to identify their category at a later stage in the code."
      ],
      "metadata": {
        "id": "btvmUnINSB0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all phonemes\n",
        "phone_list = ['p', 'k', 't', 'q', 'b', 'd', 'g', 'dx', 'f', 'th', 's', 'sh', 'v', 'dh', 'z', 'zh', 'ch', 'jh', 'm', 'n', 'ng', 'em', 'en', 'eng', 'nx', 'l', 'r', 'y', 'w', 'hh', 'hv', 'hl', 'iy', 'ey', 'aa', 'aw', 'ay', 'ao', 'oy', 'ow', 'uw', 'er', 'ax', 'ih', 'eh', 'ae', 'ah', 'uh', 'ux', 'ix', 'axr', 'ax-h']"
      ],
      "metadata": {
        "id": "lE76oJAPAHDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the various categories of the phonemes are defined, with their constituent phonemes and optimum exaggeration ratios for each of pitch, duration and energy paameters. The optimum ratios used here are obtained from the supplementary materials of the [PTeacher](https://arxiv.org/abs/2105.05182) paper.<br>Each phoneme category is a Python dictionary with the following key-value pairs:\n",
        "*   **Phoneme**: includes a single dimensional numpy array containing the phonemes under that category\n",
        "*   **Pitch**: defines the optimum exaggeration ratio for pitch of the said category\n",
        "*   **Duration**: defines the optimum exaggeration ratio for duration of the said category\n",
        "*   **Energy**: defines the optimum exaggeration ratio for energy of the said category"
      ],
      "metadata": {
        "id": "dXcAx18SaZ8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ztmqj4hbz4pO"
      },
      "outputs": [],
      "source": [
        "# Categories of phonemes and their corresponding optimum exaggeration ratios\n",
        "voiceless_stops = {\"Phoneme\" : np.array(['p', 'k', 't', 'q']), \"Pitch\" : 1.26, \"Duration\" : 1.13, \"Energy\" : 4.22}\n",
        "voiced_stops = {\"Phoneme\" : np.array(['b', 'd', 'g', 'dx']), \"Pitch\" : 1.26, \"Duration\" : 1.49, \"Energy\" : 5.29}\n",
        "\n",
        "voiceless_fricatives = {\"Phoneme\" : np.array(['f', 'th', 's', 'sh']), \"Pitch\" : 1.22, \"Duration\" : 2.76, \"Energy\" : 3.78}\n",
        "voiced_fricatives = {\"Phoneme\" : np.array(['v', 'dh', 'z', 'zh']), \"Pitch\" : 1.51, \"Duration\" : 1.64, \"Energy\" : 4.63}\n",
        "\n",
        "voiceless_affricates = {\"Phoneme\" : np.array(['ch']), \"Pitch\" : 1.19, \"Duration\" : 1.19, \"Energy\" : 3.58}\n",
        "voiced_affricates = {\"Phoneme\" : np.array(['jh']), \"Pitch\" : 1.70, \"Duration\" : 1.87, \"Energy\" : 4.64}\n",
        "\n",
        "nasals = {\"Phoneme\" : np.array(['m', 'n', 'ng', 'em', 'en', 'eng', 'nx']), \"Pitch\" : 1.32, \"Duration\" : 3.42, \"Energy\" : 1.60}\n",
        "\n",
        "laterals = {\"Phoneme\" : np.array(['l', 'r']), \"Pitch\" : 1.12, \"Duration\" : 2.78, \"Energy\" : 3.45}\n",
        "\n",
        "semi_vowels = {\"Phoneme\" : np.array(['y', 'w', 'hh', 'hv', 'hl']), \"Pitch\" : 1.24, \"Duration\" : 2.16, \"Energy\" : 2.57}\n",
        "long_vowels = {\"Phoneme\" : np.array(['iy', 'ey', 'aa', 'aw', 'ay', 'ao', 'oy', 'ow', 'uw', 'er', 'ax']), \"Pitch\" : 1.14, \"Duration\" : 1.96, \"Energy\" : 2.82}\n",
        "short_vowels = {\"Phoneme\" : np.array(['ih', 'eh', 'ae', 'ah', 'uh', 'ux', 'ix', 'axr', 'ax-h']), \"Pitch\" : 1.38, \"Duration\" : 2.15, \"Energy\" : 2.15}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the path of the audio file, which is to be modified, and its corresponding transcript file, is taken as input using the variables **wavfile** and **transcript**, respectively.<br>Note that the **audio file needs to be in .wav format**."
      ],
      "metadata": {
        "id": "ILLptLDr3mWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input section\n",
        "wavfile = input(\"Path of the .wav file: \")\n",
        "transcript = input(\"Path of the transcript file: \")"
      ],
      "metadata": {
        "id": "w8n6IbUwKK6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell, the function **scipy.io.wavfile.read** reads the .wav audio file, and returns its sampling rate in samples/sec (fs) and the data in the form of a numpy array (x_int16)."
      ],
      "metadata": {
        "id": "MZsG6V3csqbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtains sampling frequency and array of frames\n",
        "fs, x_int16 = wavread(wavfile)\n",
        "x = x_int16 / (2 ** 15 - 1)"
      ],
      "metadata": {
        "id": "3-Ft_CMOKoyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell is used for encoding the audio file using parameters obtained from reading the file in the previous cell and using the f0_method **harvest**."
      ],
      "metadata": {
        "id": "-ff14plvu2E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodes the audio file\n",
        "dat = vocoder.encode(fs, x, f0_method = 'harvest')\n",
        "ori = vocoder.encode(fs, x, f0_method = 'harvest')"
      ],
      "metadata": {
        "id": "29RWl7VsKpi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, a function get_position() is defined, which calculates the position/index of a certain timestamp in the temporal_positions array of the encoded audio file.<br>\n",
        "<br>**Parameters**\n",
        "* **time - float**: Timestamp whose position is to be determined\n",
        "\n",
        "<br>**Returns** \n",
        "* **pos - int**: Position/index of the timestamp\n",
        "\n"
      ],
      "metadata": {
        "id": "vz4dfsISvcMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculates the index of a timestamp from the temporal_positions array\n",
        "def get_position(time):\n",
        "  pos = 0\n",
        "  time1 = round((5 * round((time / 5), 3)), 3)\n",
        "\n",
        "  for i in range(0, len(ori['temporal_positions'])):\n",
        "    if ori['temporal_positions'][i] == time1:\n",
        "      pos = i\n",
        "      \n",
        "  return pos"
      ],
      "metadata": {
        "id": "9NmEDn-L9Pp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell reads the transcript file line by line, and creates a nested Python dictionary, where the the primary key is **Phoneme 'x'** (x being the phoneme number), which contains another dictionary as its value with the following key-value pairs:\n",
        "*   **Phoneme**: contains the phoneme string\n",
        "*   **Start**: contains the index/position of the starting timestamp of the said phoneme\n",
        "*   **End**: contains the index/position of the ending timestamp of the said phoneme\n",
        "\n"
      ],
      "metadata": {
        "id": "1DXMpMwgMDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reads the transcript file\n",
        "phoneme = {}\n",
        "t = 0\n",
        "\n",
        "with open(transcript, \"r\") as txtfile:\n",
        "  for line in txtfile:\n",
        "    c = 0\n",
        "\n",
        "    for word in line.split():\n",
        "      if c == 0:\n",
        "        st = float(word)\n",
        "\n",
        "      elif c == 1:\n",
        "        et = float(word)\n",
        "\n",
        "      else:\n",
        "        ph = word\n",
        "\n",
        "      c += 1\n",
        "\n",
        "    key = \"Phoneme \" + str(t)\n",
        "    phoneme[key] = {}\n",
        "\n",
        "    phoneme[key][\"Phoneme\"] = ph\n",
        "    phoneme[key][\"Start\"] = get_position(st)\n",
        "    phoneme[key][\"End\"] = get_position(et)\n",
        "\n",
        "    t += 1\n",
        "\n",
        "len_phn = len(phoneme)"
      ],
      "metadata": {
        "id": "pC_6Wmo22lSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the end bounds of the part of the audio file to be exaggerated is determined."
      ],
      "metadata": {
        "id": "pZUGqC0Ia19k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determmines the starting and ending temporal positions of the word which is to be exaggerated\n",
        "st = phoneme[\"Phoneme 0\"][\"Start\"]\n",
        "k = \"Phoneme \" + str(len(phoneme) - 1)\n",
        "et = phoneme[k][\"End\"]"
      ],
      "metadata": {
        "id": "7fETJ5fvLwRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell determines the difference between two consecutive timestamps in the 'temporal_positions' array, and rounds it upto three decimal places."
      ],
      "metadata": {
        "id": "eheOAuxro4h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = ori['temporal_positions'][1] - ori['temporal_positions'][0]\n",
        "diff = round(diff, 3)"
      ],
      "metadata": {
        "id": "QqUaD94eDvM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function pitch_modulations() is defined, which returns the pitch modified array of data, read from the audio file.<br>\n",
        "<br>**Parameters**\n",
        "* **pos1 - int**: Starting timestamp\n",
        "* **pos2 - int**: Ending timestamp\n",
        "* **factor - float**: Optimum exaggeration ratio, or factor, by which the pitch is to be modified\n",
        "* **dt - numpy array**: Array of data read from the audio file\n",
        "\n",
        "<br>**Returns** \n",
        "* **dt - numpy array**: Pitch modified array of data read from the audio file"
      ],
      "metadata": {
        "id": "An_7EofLpL2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifies the pitch in an audio\n",
        "def pitch_modulations(pos1, pos2, factor, dt):\n",
        "  dt['f0'][pos1:pos2] *= factor\n",
        "  return dt"
      ],
      "metadata": {
        "id": "sXe8XxIfTd9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function time_modulations() is defined, which returns the duration modified array of data, read from the audio file.<br>\n",
        "<br>**Parameters**\n",
        "* **pos1 - int**: Starting timestamp\n",
        "* **pos2 - int**: Ending timestamp\n",
        "* **factor - float**: Optimum exaggeration ratio, or factor, by which the duration is to be modified\n",
        "* **dt - numpy array**: Array of data read from the audio file\n",
        "\n",
        "<br>**Returns** \n",
        "* **dt - numpy array**: Duration modified array of data read from the audio file"
      ],
      "metadata": {
        "id": "YwvbWyAArbju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifies the duration in an audio\n",
        "def time_modulations(pos1, pos2, factor, dt, diff):\n",
        "  temp = []\n",
        "  c = 0\n",
        "\n",
        "  for i in range(pos1, pos2 + 1):\n",
        "    temp.append(dt['temporal_positions'][i] - dt['temporal_positions'][pos1])\n",
        "\n",
        "  for i in range(len(temp)):\n",
        "    temp[i] *= factor\n",
        "\n",
        "  for i in range(pos1, pos2 + 1):\n",
        "    dt['temporal_positions'][i] =  dt['temporal_positions'][pos1] + temp[c]\n",
        "    c += 1\n",
        "\n",
        "  for i in range(1, len(dt['temporal_positions'])):\n",
        "    if dt['temporal_positions'][i] < dt['temporal_positions'][i - 1]:\n",
        "      dt['temporal_positions'][i] = dt['temporal_positions'][i - 1] + diff\n",
        "      \n",
        "  return dt"
      ],
      "metadata": {
        "id": "QShWcAUJtWfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function energy_modulations() is defined, which returns the energy modified array of data, read from the audio file.<br>\n",
        "<br>**Parameters**\n",
        "* **pos1 - int**: Starting timestamp\n",
        "* **pos2 - int**: Ending timestamp\n",
        "* **factor - float**: Optimum exaggeration ratio, or factor, by which the energy is to be modified\n",
        "* **dt - numpy array**: Array of data read from the audio file\n",
        "\n",
        "<br>**Returns** \n",
        "* **dt - numpy array**: Energy modified array of data read from the audio file"
      ],
      "metadata": {
        "id": "Jmv8lxaZro07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifies the energy in an audio\n",
        "def energy_modulations(pos1, pos2, factor, dt):\n",
        "  dt['spectrogram'][pos1:pos2] *= factor\n",
        "  return dt"
      ],
      "metadata": {
        "id": "7_A7MeXLtg42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function search() is defined, which returns the position of a phonem in a pre-defined list of phonemes, using which its category is determined.<br>\n",
        "<br>**Parameters**\n",
        "* **ar - numpy aray**: The pre-defined Python list phone_list, containing a list of all the phonemes, defined above\n",
        "* **x - str**: Phoneme whose category is to be determined\n",
        "\n",
        "<br>**Returns** \n",
        "* **i - int**: Position of the phoneme in the pre-defined list"
      ],
      "metadata": {
        "id": "B56LXa3lhonH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determines the category of the current phoneme (using linear search)\n",
        "def search(ar, x):\n",
        "  for i in range(len(ar)):\n",
        "    if ar[i] == x:\n",
        "      return i + 1\n",
        "  return -1"
      ],
      "metadata": {
        "id": "YROflRUl-vBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell is used to segregate the phonemes under different categories, from the **phoneme** dictionary, and accordingly, perform each of pitch, duration and energy exaggeration on them using the appropriate optimum ratios."
      ],
      "metadata": {
        "id": "4bxklE3jmnhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performs various modifications on the audio phoneme-wise\n",
        "for i in phoneme:\n",
        "    phone = phoneme[i][\"Phoneme\"] # Phoneme\n",
        "    start = phoneme[i][\"Start\"] # Starting timestamp\n",
        "    end = phoneme[i][\"End\"] # Ending timestamp\n",
        "\n",
        "    pos = search(phone_list, phone)\n",
        "\n",
        "    # Voiceless stops\n",
        "    if pos <= 4 and pos != -1:\n",
        "      pf = voiceless_stops[\"Pitch\"]\n",
        "      df = voiceless_stops[\"Duration\"]\n",
        "      ef = voiceless_stops[\"Energy\"]\n",
        "\n",
        "    # Voiced stops\n",
        "    elif pos > 4 and pos <= 8:\n",
        "      pf = voiced_stops[\"Pitch\"]\n",
        "      df = voiced_stops[\"Duration\"]\n",
        "      ef = voiced_stops[\"Energy\"]\n",
        "\n",
        "    # Voiceless fricatives\n",
        "    elif pos > 8 and pos <= 12:\n",
        "      pf = voiceless_fricatives[\"Pitch\"]\n",
        "      df = voiceless_fricatives[\"Duration\"]\n",
        "      ef = voiceless_fricatives[\"Energy\"]\n",
        "\n",
        "    # Voiced fricatives\n",
        "    elif pos > 12 and pos <= 16:\n",
        "      pf = voiced_fricatives[\"Pitch\"]\n",
        "      df = voiced_fricatives[\"Duration\"]\n",
        "      ef = voiced_fricatives[\"Energy\"]\n",
        "\n",
        "    # Voiceless affricates\n",
        "    elif pos > 16 and pos <= 17:\n",
        "      pf = voiceless_affricates[\"Pitch\"]\n",
        "      df = voiceless_affricates[\"Duration\"]\n",
        "      ef = voiceless_affricates[\"Energy\"]\n",
        "\n",
        "    # Voiced affricates\n",
        "    elif pos > 17 and pos <= 18:\n",
        "      pf = voiced_affricates[\"Pitch\"]\n",
        "      df = voiced_affricates[\"Duration\"]\n",
        "      ef = voiced_affricates[\"Energy\"]\n",
        "\n",
        "    # Nasals\n",
        "    elif pos > 18 and pos <= 25:\n",
        "      pf = nasals[\"Pitch\"]\n",
        "      df = nasals[\"Duration\"]\n",
        "      ef = nasals[\"Energy\"]\n",
        "\n",
        "    # Laterals\n",
        "    elif pos > 25 and pos <= 27:\n",
        "      pf = laterals[\"Pitch\"]\n",
        "      df = laterals[\"Duration\"]\n",
        "      ef = laterals[\"Energy\"]\n",
        "\n",
        "    # Semi-vowels\n",
        "    elif pos > 27 and pos <= 32:\n",
        "      pf = semi_vowels[\"Pitch\"]\n",
        "      df = semi_vowels[\"Duration\"]\n",
        "      ef = semi_vowels[\"Energy\"]\n",
        "\n",
        "    # Long vowels\n",
        "    elif pos > 32 and pos <= 43:\n",
        "      pf = long_vowels[\"Pitch\"]\n",
        "      df = long_vowels[\"Duration\"]\n",
        "      ef = long_vowels[\"Energy\"]\n",
        "\n",
        "    # Short vowels\n",
        "    elif pos != -1:\n",
        "      pf = short_vowels[\"Pitch\"]\n",
        "      df = short_vowels[\"Duration\"]\n",
        "      ef = short_vowels[\"Energy\"]\n",
        "      \n",
        "    dat = pitch_modulations(start, end, pf, dat)\n",
        "    dat = time_modulations(start, end, df, dat, diff)\n",
        "    dat = energy_modulations(start, end, ef, dat)"
      ],
      "metadata": {
        "id": "jymEJY6wOAeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the modulations have been done the modified array of data from the audio file, **dat**, is decoded using the decode() function of the vocoder."
      ],
      "metadata": {
        "id": "zFe4oFvnpPOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decodes the modified audio file and writes it onto a new file\n",
        "dat1 = vocoder.decode(dat)"
      ],
      "metadata": {
        "id": "G-9uAZYa76DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, this cell is solely used for the purpose of storing the modified audio file. It follows the format of **(Low/High) Proficiency/(Word/Phoneme) Modifications/(Word/Phoneme)_(Number)**"
      ],
      "metadata": {
        "id": "nAllzJXIp7NC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len_phn == 1:\n",
        "  ph_num = transcript.rindex(\"_\") + 1\n",
        "  wrd_num = transcript.rindex(\"/\") - 1\n",
        "\n",
        "  if ph_num < 10:\n",
        "    new_wavfile = wavfile[0:(len(wavfile) - 19)] + \"/\" + \"Low Proficiency/Phoneme_Modifications/Phoneme_\" + transcript[ph_num:(ph_num + 1)] + \".wav\"\n",
        "\n",
        "  elif ph_num >=10:\n",
        "    # new_wavfile = wavfile[0:(len(wavfile) - 19)] + \"/\" + \"Low Proficiency/Phoneme_Modifications/Phoneme_\" + transcript[ph_num:(ph_num + 2)] + \".wav\"\n",
        "    new_wavfile = wavfile[0:(len(wavfile) - 19)] + \"/\" + \"Low Proficiency/Phoneme_Modifications/Word_\" + transcript[wrd_num:(wrd_num + 1)] + \"/Phoneme_\" + transcript[ph_num:(ph_num + 2)] + \".wav\"\n",
        "\n",
        "elif len_phn > 1:\n",
        "  wrd_num = transcript.rindex(\"_\") + 1\n",
        "\n",
        "  if wrd_num < 10:\n",
        "    new_wavfile = wavfile[0:(len(wavfile) - 19)] + \"/\" + \"Low Proficiency/Word_Modifications/Word_\" + transcript[wrd_num:(wrd_num + 1)] + \"wav\"\n",
        "\n",
        "  elif wrd_num >= 10:\n",
        "    new_wavfile = wavfile[0:(len(wavfile) - 19)] + \"/\" + \"Low Proficiency/Word_Modifications/Word_\" + transcript[wrd_num:(wrd_num + 1)] + \".wav\"\n",
        "\n",
        "wavwrite(new_wavfile, fs, (dat1['out'] * (2 ** 15)).astype(np.int16))"
      ],
      "metadata": {
        "id": "LDLC3nJ2p3fU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}